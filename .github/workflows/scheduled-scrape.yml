name: Scheduled Knowledge Base Refresh

"on":
  schedule:
    - cron: '0 3 * * 0'  # Every Sunday at 3 AM UTC
  workflow_dispatch: {}   # Allow manual trigger

jobs:
  scrape-and-seed:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: venture-x-os/package-lock.json

      - name: Install dependencies
        run: cd venture-x-os && npm ci

      - name: Install Playwright Chromium
        run: cd venture-x-os && npx playwright install chromium

      - name: Run Capital One scraper (Tier 0)
        run: cd venture-x-os && npm run scrape:capitalone
        continue-on-error: true
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}

      - name: Run Tier 1 scraper (guide sites)
        run: cd venture-x-os && npm run scrape:tier1
        continue-on-error: true
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}

      - name: Run Reddit scraper (Tier 2)
        run: cd venture-x-os && npm run seed:test-scraper
        continue-on-error: true
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}

      - name: Seed vector store
        run: cd venture-x-os && npm run seed
        continue-on-error: true
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}

      - name: Commit scraped data
        run: |
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"
          git add venture-x-os/data/
          git diff --staged --quiet || git commit -m "chore: refresh scraped knowledge base data [skip ci]"
          git push
